{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e4be4c-6bd6-4252-a8e6-8e8fb8ed45a1",
   "metadata": {},
   "source": [
    "### Uniendo todos los meses en un solo dataframe por año"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c09de4-0276-46cb-86f6-bafa7fd43909",
   "metadata": {},
   "source": [
    "Dos carpetas:\n",
    "- data pura (extraída)\n",
    "- data limpia (después de muestrear)\n",
    "\n",
    "Se hizo un subsampleo, porque originalmente eran millones de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2b89ddd2-e469-434d-a73f-51a239ee4a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a458ef46-0fe3-4271-8d13-4630f56b5005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando archivos de 2011...\n",
      "Procesando archivo: 2011-01.csv\n",
      "  Muestra tomada: 10000 de 194027 registros\n",
      "Procesando archivo: 2011-02.csv\n",
      "  Muestra tomada: 10000 de 213473 registros\n",
      "Procesando archivo: 2011-03.csv\n",
      "  Muestra tomada: 10000 de 263132 registros\n",
      "Procesando archivo: 2011-04.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esco1\\AppData\\Local\\Temp\\ipykernel_23500\\2363010276.py:36: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(archivo)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Muestra tomada: 10000 de 226501 registros\n",
      "Procesando archivo: 2011-05.csv\n",
      "  Muestra tomada: 10000 de 238118 registros\n",
      "Procesando archivo: 2011-06.csv\n",
      "  Muestra tomada: 10000 de 220447 registros\n",
      "Procesando archivo: 2011-07.csv\n",
      "  Muestra tomada: 10000 de 188102 registros\n",
      "Procesando archivo: 2011-08.csv\n",
      "  Muestra tomada: 10000 de 212463 registros\n",
      "Procesando archivo: 2011-09.csv\n",
      "  Muestra tomada: 10000 de 207894 registros\n",
      "Procesando archivo: 2011-10.csv\n",
      "  Muestra tomada: 10000 de 200880 registros\n",
      "Procesando archivo: 2011-11.csv\n",
      "  Muestra tomada: 10000 de 198242 registros\n",
      "Procesando archivo: 2011-12.csv\n",
      "  Muestra tomada: 10000 de 179684 registros\n",
      "Total de registros después del muestreo: 120000\n",
      "\n",
      "Procesando archivos de 2012...\n",
      "Procesando archivo: 2012-01.csv\n",
      "  Muestra tomada: 10000 de 192272 registros\n",
      "Procesando archivo: 2012-02.csv\n",
      "  Muestra tomada: 10000 de 186300 registros\n",
      "Procesando archivo: 2012-03.csv\n",
      "  Muestra tomada: 10000 de 205314 registros\n",
      "Procesando archivo: 2012-04.csv\n",
      "  Muestra tomada: 10000 de 187942 registros\n",
      "Procesando archivo: 2012-05.csv\n",
      "  Muestra tomada: 10000 de 224724 registros\n",
      "Procesando archivo: 2012-06.csv\n",
      "  Muestra tomada: 10000 de 197067 registros\n",
      "Procesando archivo: 2012-07.csv\n",
      "  Muestra tomada: 10000 de 194235 registros\n",
      "Procesando archivo: 2012-08.csv\n",
      "  Muestra tomada: 10000 de 194763 registros\n",
      "Procesando archivo: 2012-09.csv\n",
      "  Muestra tomada: 10000 de 210666 registros\n",
      "Procesando archivo: 2012-10.csv\n",
      "  Muestra tomada: 10000 de 309075 registros\n",
      "Procesando archivo: 2012-11.csv\n",
      "  Muestra tomada: 10000 de 320525 registros\n",
      "Procesando archivo: 2012-12.csv\n",
      "  Muestra tomada: 10000 de 315034 registros\n",
      "Total de registros después del muestreo: 120000\n",
      "\n",
      "Procesando archivos de 2023...\n",
      "Procesando archivo: 2023-01.csv\n",
      "  Muestra tomada: 10000 de 586433 registros\n",
      "Procesando archivo: 2023-02.csv\n",
      "  Muestra tomada: 10000 de 664982 registros\n",
      "Procesando archivo: 2023-03.csv\n",
      "  Muestra tomada: 10000 de 818034 registros\n",
      "Procesando archivo: 2023-04.csv\n",
      "  Muestra tomada: 10000 de 813629 registros\n",
      "Procesando archivo: 2023-05.csv\n",
      "  Muestra tomada: 10000 de 945163 registros\n",
      "Procesando archivo: 2023-06.csv\n",
      "  Muestra tomada: 10000 de 1010000 registros\n",
      "Procesando archivo: 2023-07.csv\n",
      "  Muestra tomada: 10000 de 999713 registros\n",
      "Procesando archivo: 2023-08.csv\n",
      "  Muestra tomada: 10000 de 37072 registros\n",
      "Procesando archivo: 2023-09.csv\n",
      "  Muestra tomada: 10000 de 40156 registros\n",
      "Procesando archivo: 2023-10.csv\n",
      "  Muestra tomada: 10000 de 44972 registros\n",
      "Procesando archivo: 2023-11.csv\n",
      "  Muestra tomada: 10000 de 44185 registros\n",
      "Procesando archivo: 2023-12.csv\n",
      "  Muestra tomada: 10000 de 30733 registros\n",
      "Total de registros después del muestreo: 120000\n",
      "\n",
      "Procesando archivos de 2024...\n",
      "Procesando archivo: 2024-01.csv\n",
      "  Muestra tomada: 10000 de 48958 registros\n",
      "Procesando archivo: 2024-02.csv\n",
      "  Muestra tomada: 10000 de 55408 registros\n",
      "Procesando archivo: 2024-03.csv\n",
      "  Muestra tomada: 10000 de 57156 registros\n",
      "Procesando archivo: 2024-04.csv\n",
      "  Muestra tomada: 10000 de 63264 registros\n",
      "Procesando archivo: 2024-05.csv\n",
      "  Muestra tomada: 10000 de 68302 registros\n",
      "Procesando archivo: 2024-06.csv\n",
      "  Muestra tomada: 10000 de 61925 registros\n",
      "Procesando archivo: 2024-07.csv\n",
      "  Muestra tomada: 10000 de 58257 registros\n",
      "Procesando archivo: 2024-08.csv\n",
      "  Muestra tomada: 10000 de 1891319 registros\n",
      "Procesando archivo: 2024-09.csv\n",
      "  Muestra tomada: 10000 de 1852179 registros\n",
      "Procesando archivo: 2024-10.csv\n",
      "  Muestra tomada: 10000 de 2054609 registros\n",
      "Procesando archivo: 2024-11.csv\n",
      "  Muestra tomada: 10000 de 1942474 registros\n",
      "Procesando archivo: 2024-12.csv\n",
      "  Muestra tomada: 10000 de 1680650 registros\n",
      "Total de registros después del muestreo: 120000\n",
      "\n",
      "--- RESUMEN ---\n",
      "Total de registros en muestra 2011: 120000\n",
      "Total de registros en muestra 2012: 120000\n",
      "Total de registros en muestra 2023: 120000\n",
      "Total de registros en muestra 2024: 120000\n",
      "Muestra de 2011 guardada correctamente\n",
      "Muestra de 2012 guardada correctamente\n",
      "Muestra de 2023 guardada correctamente\n",
      "Muestra de 2024 guardada correctamente\n"
     ]
    }
   ],
   "source": [
    "def unir_csv_ecobici(directorio, patron, muestra_tamaño=1000, semilla=42):\n",
    "    \"\"\"\n",
    "    Une una muestra de los archivos CSV de Ecobici en un DataFrame\n",
    "\n",
    "    Args:\n",
    "        directorio (str): Ruta al directorio donde se encuentran los archivos CSV.\n",
    "        patron (str): Patrón para encontrar los archivos.\n",
    "        muestra_tamaño (int): Número de filas a muestrear de cada archivo.\n",
    "        semilla (int): Semilla para reproducibilidad del muestreo aleatorio.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame combinado con las muestras de los datos\n",
    "    \"\"\"\n",
    "    # Patrón para encontrar archivos que coincidan con el formato\n",
    "    ruta_patron = os.path.join(directorio, patron)\n",
    "    \n",
    "    # Lista para almacenar los DataFrames individuales\n",
    "    dfs = []\n",
    "    # Establecer semilla para reproducibilidad\n",
    "    random.seed(semilla)\n",
    "    \n",
    "    # Buscar todos los archivos que coincidan con el patrón\n",
    "    archivos = glob.glob(ruta_patron)\n",
    "    for archivo in archivos:\n",
    "        try:\n",
    "            # Extraer el nombre del archivo\n",
    "            nombre_archivo = os.path.basename(archivo)\n",
    "            print(f\"Procesando archivo: {nombre_archivo}\")\n",
    "            \n",
    "            # Leer el archivo CSV\n",
    "            df = pd.read_csv(archivo)\n",
    "            \n",
    "            # Tomar una muestra si el DataFrame tiene más filas que muestra_tamaño\n",
    "            if len(df) > muestra_tamaño:\n",
    "                df_muestra = df.sample(n=muestra_tamaño, random_state=semilla)\n",
    "                print(f\"  Muestra tomada: {muestra_tamaño} de {len(df)} registros\")\n",
    "            else:\n",
    "                df_muestra = df\n",
    "                print(f\"  Archivo completo (menos de {muestra_tamaño} registros): {len(df)} registros\")\n",
    "            \n",
    "            # Agregar información del mes/año al DataFrame\n",
    "            mes_año = nombre_archivo.split('.')[0]  # Asumiendo formato \"YYYY-MM.csv\"\n",
    "            df_muestra['archivo_origen'] = mes_año\n",
    "            dfs.append(df_muestra)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar {nombre_archivo}: {str(e)}\")\n",
    "    \n",
    "    if dfs:\n",
    "        df_combinado = pd.concat(dfs, ignore_index=True)\n",
    "        print(f\"Total de registros después del muestreo: {len(df_combinado)}\")\n",
    "        return df_combinado\n",
    "    else:\n",
    "        print(f\"No se encontraron archivos con el patrón: {ruta_patron}\")\n",
    "        return pd.DataFrame()  \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(\"./data_limpia\", exist_ok=True) # ubicación/path actual\n",
    "    \n",
    "    MUESTRA_TAMAÑO = 10000 \n",
    "    \n",
    "    print(\"Procesando archivos de 2011...\")\n",
    "    df_ecobici_2011 = unir_csv_ecobici(\"data_pura\", \"2011-*.csv\", muestra_tamaño=MUESTRA_TAMAÑO)\n",
    "    \n",
    "    print(\"\\nProcesando archivos de 2012...\")\n",
    "    df_ecobici_2012 = unir_csv_ecobici(\"data_pura\", \"2012-*.csv\", muestra_tamaño=MUESTRA_TAMAÑO)\n",
    "    \n",
    "    print(\"\\nProcesando archivos de 2023...\")\n",
    "    df_ecobici_2023 = unir_csv_ecobici(\"data_pura\", \"2023-*.csv\", muestra_tamaño=MUESTRA_TAMAÑO)\n",
    "    \n",
    "    print(\"\\nProcesando archivos de 2024...\")\n",
    "    df_ecobici_2024 = unir_csv_ecobici(\"data_pura\", \"2024-*.csv\", muestra_tamaño=MUESTRA_TAMAÑO)\n",
    "    \n",
    "    # Mostrar resumen\n",
    "    print(\"\\n--- RESUMEN ---\")\n",
    "    print(f\"Total de registros en muestra 2011: {len(df_ecobici_2011)}\")\n",
    "    print(f\"Total de registros en muestra 2012: {len(df_ecobici_2012)}\")\n",
    "    print(f\"Total de registros en muestra 2023: {len(df_ecobici_2023)}\")\n",
    "    print(f\"Total de registros en muestra 2024: {len(df_ecobici_2024)}\")\n",
    "    \n",
    "    # Guardar los DataFrames muestreados\n",
    "    if not df_ecobici_2011.empty:\n",
    "        df_ecobici_2011.to_csv(os.path.join(\"./data_limpia\", \"ecobici_2011_muestra.csv\"), index=False)\n",
    "        print(\"Muestra de 2011 guardada correctamente\")\n",
    "    \n",
    "    if not df_ecobici_2012.empty:\n",
    "        df_ecobici_2012.to_csv(os.path.join(\"./data_limpia\", \"ecobici_2012_muestra.csv\"), index=False)\n",
    "        print(\"Muestra de 2012 guardada correctamente\")\n",
    "    \n",
    "    if not df_ecobici_2023.empty:\n",
    "        df_ecobici_2023.to_csv(os.path.join(\"./data_limpia\", \"ecobici_2023_muestra.csv\"), index=False)\n",
    "        print(\"Muestra de 2023 guardada correctamente\")\n",
    "    \n",
    "    if not df_ecobici_2024.empty:\n",
    "        df_ecobici_2024.to_csv(os.path.join(\"./data_limpia\", \"ecobici_2024_muestra.csv\"), index=False)\n",
    "        print(\"Muestra de 2024 guardada correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b93c83-26c0-4a82-a80e-9c3c3d24b9e4",
   "metadata": {},
   "source": [
    "df2023.drop(columns=[\"Fecha_Arribo\"])\n",
    "df2024.drop(columns=[\"Fecha_Arribo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fe0e8485-bfca-4858-a6d8-b5faa4ef82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2011 = pd.read_csv(\"data_limpia/ecobici_2011_muestra.csv\")\n",
    "df2012 = pd.read_csv(\"data_limpia/ecobici_2012_muestra.csv\")\n",
    "df2023 = pd.read_csv(\"data_limpia/ecobici_2023_muestra.csv\")\n",
    "df2024 = pd.read_csv(\"data_limpia/ecobici_2024_muestra.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8388d01a-938b-4dd6-98c8-f1b46dd92efd",
   "metadata": {},
   "source": [
    "### Mucha data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "32380ba8-db2d-40ef-bbdd-785cbabee313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esco1\\AppData\\Local\\Temp\\ipykernel_23500\\1687557169.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2011 = pd.read_csv(\"data_limpia/ecobici_2011_completo.csv\")\n",
      "C:\\Users\\esco1\\AppData\\Local\\Temp\\ipykernel_23500\\1687557169.py:4: DtypeWarning: Columns (7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2024 = pd.read_csv(\"data_limpia/ecobici_2024_completo.csv\")\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 600. MiB for an array with shape (8, 9834501) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m df2012 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_limpia/ecobici_2012_completo.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m df2023 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_limpia/ecobici_2023_completo.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m df2024 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_limpia/ecobici_2024_completo.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[1;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[0;32m   1969\u001b[0m         new_col_dict,\n\u001b[0;32m   1970\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   1971\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   1972\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write(),\n\u001b[0;32m   1973\u001b[0m     )\n\u001b[0;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[0;32m    153\u001b[0m         arrays, axes, consolidate\u001b[38;5;241m=\u001b[39mconsolidate, refs\u001b[38;5;241m=\u001b[39mrefs\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2144\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2142\u001b[0m     raise_construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axes, e)\n\u001b[0;32m   2143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[1;32m-> 2144\u001b[0m     mgr\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m   2145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1788\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m _consolidate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2267\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2269\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2270\u001b[0m         \u001b[38;5;28mlist\u001b[39m(group_blocks), dtype\u001b[38;5;241m=\u001b[39mdtype, can_consolidate\u001b[38;5;241m=\u001b[39m_can_consolidate\n\u001b[0;32m   2271\u001b[0m     )\n\u001b[0;32m   2272\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2301\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2298\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2300\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2301\u001b[0m new_values \u001b[38;5;241m=\u001b[39m new_values[argsort]\n\u001b[0;32m   2302\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2304\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 600. MiB for an array with shape (8, 9834501) and data type object"
     ]
    }
   ],
   "source": [
    "df2011 = pd.read_csv(\"data_limpia/ecobici_2011_completo.csv\")\n",
    "df2012 = pd.read_csv(\"data_limpia/ecobici_2012_completo.csv\")\n",
    "df2024 = pd.read_csv(\"data_limpia/ecobici_2023_completo.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
